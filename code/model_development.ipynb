{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "model_development.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAdAiRAV-tTN"
      },
      "source": [
        "# For reading, visualizing, and preprocessing data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import RFE, RFECV\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "import os \n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "KbUs_KDd-tTa"
      },
      "source": [
        "#Importing data and setting outcome variable\n",
        "full_df = pd.read_csv(base_dir + 'event_df.csv')\n",
        "full_df['Y'] = (full_df['labresult'] < 72).astype(int)\n",
        "model_df = full_df.dropna()\n",
        "\n",
        "#Train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(model_df.drop(['Y', 'labresult'], axis = 1), model_df['Y'], test_size = 0.20,\n",
        "                                                    random_state = 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVnTCjOR-tTc"
      },
      "source": [
        "#Classifier options\n",
        "\n",
        "#RECV pipeline and code adapted from https://gist.github.com/frank-ceballos/c97346a72e5c727d1a158c5caebc00c6\n",
        "\n",
        "classifiers = {}\n",
        "classifiers.update({\"LR\" : LogisticRegression()})\n",
        "classifiers.update({\"XGB\": XGBClassifier()})\n",
        "classifiers.update({\"AdaBoost\": AdaBoostClassifier()})\n",
        "classifiers.update({\"Bagging\": BaggingClassifier()})\n",
        "classifiers.update({\"Random Forest\": RandomForestClassifier()})\n",
        "classifiers.update({\"Gradient Boosting\": GradientBoostingClassifier()})\n",
        "classifiers.update({\"Extra Trees Ensemble\": ExtraTreesClassifier()})\n",
        "classifiers.update({\"DTC\": DecisionTreeClassifier()})\n",
        "classifiers.update({\"ETC\": ExtraTreeClassifier()})\n",
        "\n",
        "classifiers.update({\"LDA\": LinearDiscriminantAnalysis()})\n",
        "classifiers.update({\"QDA\": QuadraticDiscriminantAnalysis()})\n",
        "\n",
        "classifiers.update({\"Ridge\": RidgeClassifier()})\n",
        "classifiers.update({\"SGD\": SGDClassifier()})\n",
        "classifiers.update({\"BNB\": BernoulliNB()})\n",
        "classifiers.update({\"GNB\": GaussianNB()})\n",
        "classifiers.update({\"KNN\": KNeighborsClassifier()})\n",
        "classifiers.update({\"MLP\": MLPClassifier()})\n",
        "classifiers.update({\"LSVC\": LinearSVC()})\n",
        "classifiers.update({\"NuSVC\": NuSVC()})\n",
        "classifiers.update({\"SVC\": SVC()})\n",
        "\n",
        "\n",
        "\n",
        "# Create dict of decision function labels\n",
        "DECISION_FUNCTIONS = {\"Ridge\", \"SGD\", \"LSVC\", \"NuSVC\", \"SVC\"}\n",
        "\n",
        "# Create dict for classifiers with feature_importances_ attribute\n",
        "FEATURE_IMPORTANCE = {\"Gradient Boosting\", \"Extra Trees Ensemble\", \"Random Forest\"}\n",
        "\n",
        "# Initiate parameter grid\n",
        "parameters = {}\n",
        "\n",
        "parameters.update({ \"LR\" : {'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear'], \n",
        "                    'classifier__C' : [100, 10, 1.0, 0.1, 0.01],\n",
        "                    'classifier__penalty': ['l2', 'l1'],\n",
        "                     \"classifier__n_jobs\": [-1]}})\n",
        "\n",
        "parameters.update({ \"XGB\" : {\"classifier__learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
        "                             \"classifier__max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
        "                             \"classifier__min_child_weight\" : [ 1, 3, 5, 7 ],\n",
        "                              \"classifier__gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
        "                            \"classifier__colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ],\n",
        "                            \"classifier__n_jobs\": [-1] }})\n",
        "# Update dict with LDA\n",
        "parameters.update({\"LDA\": {\"classifier__solver\": [\"svd\"], \n",
        "                                         }})\n",
        "\n",
        "# Update dict with QDA\n",
        "parameters.update({\"QDA\": {\"classifier__reg_param\":[0.01*ii for ii in range(0, 101)], \n",
        "                                         }})\n",
        "# Update dict with AdaBoost\n",
        "parameters.update({\"AdaBoost\": { \n",
        "                                \"classifier__base_estimator\": [DecisionTreeClassifier(max_depth = ii) for ii in range(1,6)],\n",
        "                                \"classifier__n_estimators\": [200],\n",
        "                                \"classifier__learning_rate\": [0.001, 0.01, 0.05, 0.1, 0.25, 0.50, 0.75, 1.0]\n",
        "                                 }})\n",
        "\n",
        "# Update dict with Bagging\n",
        "parameters.update({\"Bagging\": { \n",
        "                                \"classifier__base_estimator\": [DecisionTreeClassifier(max_depth = ii) for ii in range(1,6)],\n",
        "                                \"classifier__n_estimators\": [200],\n",
        "                                \"classifier__max_features\": [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "                                \"classifier__n_jobs\": [-1]\n",
        "                                }})\n",
        "\n",
        "# Update dict with Gradient Boosting\n",
        "parameters.update({\"Gradient Boosting\": { \n",
        "                                        \"classifier__learning_rate\":[0.15,0.1,0.05,0.01,0.005,0.001], \n",
        "                                        \"classifier__n_estimators\": [200],\n",
        "                                        \"classifier__max_depth\": [2,3,4,5,6],\n",
        "                                        \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
        "                                        \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
        "                                        \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
        "                                        \"classifier__subsample\": [0.8, 0.9, 1]\n",
        "                                         }})\n",
        "\n",
        "\n",
        "# Update dict with Extra Trees\n",
        "parameters.update({\"Extra Trees Ensemble\": { \n",
        "                                            \"classifier__n_estimators\": [200],\n",
        "                                            \"classifier__class_weight\": [None, \"balanced\"],\n",
        "                                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
        "                                            \"classifier__max_depth\" : [3, 4, 5, 6, 7, 8],\n",
        "                                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
        "                                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
        "                                            \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
        "                                            \"classifier__n_jobs\": [-1]\n",
        "                                             }})\n",
        "\n",
        "\n",
        "# Update dict with Random Forest Parameters\n",
        "parameters.update({\"Random Forest\": { \n",
        "                                    \"classifier__n_estimators\": [200],\n",
        "                                    \"classifier__class_weight\": [None, \"balanced\"],\n",
        "                                    \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
        "                                    \"classifier__max_depth\" : [3, 4, 5, 6, 7, 8],\n",
        "                                    \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
        "                                    \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
        "                                    \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
        "                                    \"classifier__n_jobs\": [-1]\n",
        "                                     }})\n",
        "\n",
        "# Update dict with Ridge\n",
        "parameters.update({\"Ridge\": { \n",
        "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0]\n",
        "                             }})\n",
        "\n",
        "# Update dict with SGD Classifier\n",
        "parameters.update({\"SGD\": { \n",
        "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0],\n",
        "                            \"classifier__penalty\": [\"l1\", \"l2\"],\n",
        "                            \"classifier__n_jobs\": [-1]\n",
        "                             }})\n",
        "\n",
        "\n",
        "# Update dict with BernoulliNB Classifier\n",
        "parameters.update({\"BNB\": { \n",
        "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0]\n",
        "                             }})\n",
        "\n",
        "# Update dict with GaussianNB Classifier\n",
        "parameters.update({\"GNB\": { \n",
        "                            \"classifier__var_smoothing\": [1e-9, 1e-8,1e-7, 1e-6, 1e-5]\n",
        "                             }})\n",
        "\n",
        "# Update dict with K Nearest Neighbors Classifier\n",
        "parameters.update({\"KNN\": { \n",
        "                            \"classifier__n_neighbors\": list(range(1,31)),\n",
        "                            \"classifier__p\": [1, 2, 3, 4, 5],\n",
        "                            \"classifier__leaf_size\": [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
        "                            \"classifier__n_jobs\": [-1]\n",
        "                             }})\n",
        "\n",
        "# Update dict with MLPClassifier\n",
        "parameters.update({\"MLP\": { \n",
        "                            \"classifier__hidden_layer_sizes\": [(5), (10), (5,5), (10,10), (5,5,5), (10,10,10)],\n",
        "                            \"classifier__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
        "                            \"classifier__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
        "                            \"classifier__max_iter\": [100, 200, 300, 500, 1000, 2000],\n",
        "                            \"classifier__alpha\": list(10.0 ** -np.arange(1, 10)),\n",
        "                             }})\n",
        "\n",
        "parameters.update({\"LSVC\": { \n",
        "                            \"classifier__penalty\": [\"l2\"],\n",
        "                            \"classifier__C\": [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100]\n",
        "                             }})\n",
        "\n",
        "parameters.update({\"NuSVC\": { \n",
        "                            \"classifier__nu\": [0.25, 0.50, 0.75],\n",
        "                            \"classifier__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
        "                            \"classifier__degree\": [1,2,3,4,5,6],\n",
        "                             }})\n",
        "\n",
        "parameters.update({\"SVC\": { \n",
        "                            \"classifier__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
        "                            \"classifier__gamma\": [\"auto\"],\n",
        "                            \"classifier__C\": [0.1, 0.5, 1, 5, 10, 50, 100],\n",
        "                            \"classifier__degree\": [1, 2, 3, 4, 5, 6]\n",
        "                             }})\n",
        "\n",
        "\n",
        "# Update dict with Decision Tree Classifier\n",
        "parameters.update({\"DTC\": { \n",
        "                            \"classifier__criterion\" :[\"gini\", \"entropy\"],\n",
        "                            \"classifier__splitter\": [\"best\", \"random\"],\n",
        "                            \"classifier__class_weight\": [None, \"balanced\"],\n",
        "                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
        "                            \"classifier__max_depth\" : [1,2,3, 4, 5, 6, 7, 8],\n",
        "                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
        "                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
        "                             }})\n",
        "\n",
        "# Update dict with Extra Tree Classifier\n",
        "parameters.update({\"ETC\": { \n",
        "                            \"classifier__criterion\" :[\"gini\", \"entropy\"],\n",
        "                            \"classifier__splitter\": [\"best\", \"random\"],\n",
        "                            \"classifier__class_weight\": [None, \"balanced\"],\n",
        "                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
        "                            \"classifier__max_depth\" : [1,2,3, 4, 5, 6, 7, 8],\n",
        "                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
        "                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
        "                             }})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxxwhAhO-tTm"
      },
      "source": [
        "# Define classifier to use as the base of the recursive feature elimination algorithm\n",
        "selected_classifier = \"XGB\"\n",
        "classifier = classifiers[selected_classifier]\n",
        "\n",
        "# Tune classifier (Took = 4.8 minutes)\n",
        "    \n",
        "# Scale features via Z-score normalization\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Define steps in pipeline\n",
        "#steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
        "steps = [(\"classifier\", classifier)]\n",
        "\n",
        "# Initialize Pipeline object\n",
        "pipeline = Pipeline(steps = steps)\n",
        "  \n",
        "# Define parameter grid\n",
        "param_grid = parameters[selected_classifier]\n",
        "\n",
        "# Initialize GridSearch object\n",
        "gscv = GridSearchCV(pipeline, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = \"roc_auc\")\n",
        "                  \n",
        "# Fit gscv\n",
        "print(f\"Now tuning {selected_classifier}. Go grab a beer or something.\")\n",
        "gscv.fit(X_train, np.ravel(y_train))  \n",
        "\n",
        "# Get best parameters and score\n",
        "best_params = gscv.best_params_\n",
        "best_score = gscv.best_score_\n",
        "        \n",
        "# Update classifier parameters\n",
        "tuned_params = {item[12:]: best_params[item] for item in best_params}\n",
        "classifier.set_params(**tuned_params)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ5QVViX-tTn"
      },
      "source": [
        "# Select Features using RFECV\n",
        "class PipelineRFE(Pipeline):\n",
        "    # Source: https://ramhiser.com/post/2018-03-25-feature-selection-with-scikit-learn-pipeline/\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        super(PipelineRFE, self).fit(X, y, **fit_params)\n",
        "        self.feature_importances_ = self.steps[-1][-1].feature_importances_\n",
        "        return self\n",
        "\n",
        "steps = [(\"classifier\", classifier)]\n",
        "\n",
        "pipe = PipelineRFE(steps = steps)\n",
        "\n",
        "# Initialize RFECV object\n",
        "feature_selector = RFECV(pipe, cv = 10, step = 1, scoring = \"roc_auc\", verbose = 1)\n",
        "\n",
        "# Fit RFECV\n",
        "feature_selector.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "# Get selected features\n",
        "feature_names = X_train.columns\n",
        "selected_features = feature_names[feature_selector.support_].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7shUMUKN-tTn"
      },
      "source": [
        "# Get Performance Data\n",
        "performance_curve = {\"Number of Features\": list(range(1, len(feature_names) + 1)),\n",
        "                    \"AUC\": feature_selector.grid_scores_}\n",
        "performance_curve = pd.DataFrame(performance_curve)\n",
        "\n",
        "# Performance vs Number of Features\n",
        "# Set graph style\n",
        "sns.set(font_scale = 1.75)\n",
        "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
        "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
        "               'ytick.color': '0.4'})\n",
        "colors = sns.color_palette(\"RdYlGn\", 20)\n",
        "line_color = colors[3]\n",
        "marker_colors = colors[-1]\n",
        "\n",
        "# Plot\n",
        "f, ax = plt.subplots(figsize=(13, 6.5))\n",
        "sns.lineplot(x = \"Number of Features\", y = \"AUC\", data = performance_curve,\n",
        "             color = line_color, lw = 4, ax = ax)\n",
        "sns.regplot(x = performance_curve[\"Number of Features\"], y = performance_curve[\"AUC\"],\n",
        "            color = marker_colors, fit_reg = False, scatter_kws = {\"s\": 200}, ax = ax)\n",
        "\n",
        "# Axes limits\n",
        "plt.xlim(0.5, len(feature_names)+0.5)\n",
        "plt.ylim(0.60, 1)\n",
        "\n",
        "# Generate a bolded horizontal line at y = 0\n",
        "ax.axhline(y = 0.625, color = 'black', linewidth = 1.3, alpha = .7)\n",
        "\n",
        "# Turn frame off\n",
        "ax.set_frame_on(False)\n",
        "\n",
        "# Tight layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save Figure\n",
        "plt.savefig(base_dir + \"performance_curve.png\", dpi = 1080)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0q37ngv-tTo"
      },
      "source": [
        "# Define pipeline for RFECV\n",
        "steps = [(\"classifier\", classifier)]\n",
        "\n",
        "pipe = PipelineRFE(steps = steps)\n",
        "\n",
        "# Initialize RFE object\n",
        "feature_selector = RFE(pipe, n_features_to_select = 10, step = 1, verbose = 1)\n",
        "\n",
        "# Fit RFE\n",
        "feature_selector.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "# Get selected features labels\n",
        "feature_names = X_train.columns\n",
        "selected_features = feature_names[feature_selector.support_].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbKjreUW-tTo"
      },
      "source": [
        "# Get selected features data set\n",
        "X_train = X_train[selected_features]\n",
        "X_test = X_test[selected_features]\n",
        "\n",
        "# Train classifier\n",
        "classifier.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "# Get feature importance\n",
        "feature_importance = pd.DataFrame(selected_features, columns = [\"Feature Label\"])\n",
        "feature_importance[\"Feature Importance\"] = classifier.feature_importances_\n",
        "\n",
        "# Sort by feature importance\n",
        "feature_importance = feature_importance.sort_values(by=\"Feature Importance\", ascending=False)\n",
        "\n",
        "# Set graph style\n",
        "sns.set(font_scale = 1.75)\n",
        "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
        "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
        "               'ytick.color': '0.4'})\n",
        "\n",
        "# Set figure size and create barplot\n",
        "f, ax = plt.subplots(figsize=(12, 9))\n",
        "sns.barplot(x = \"Feature Importance\", y = \"Feature Label\",\n",
        "            palette = reversed(sns.color_palette('YlOrRd', 15)),  data = feature_importance)\n",
        "\n",
        "# Generate a bolded horizontal line at y = 0\n",
        "ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
        "\n",
        "# Turn frame off\n",
        "ax.set_frame_on(False)\n",
        "\n",
        "# Tight layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save Figure\n",
        "plt.savefig(base_dir + \"feature_importance.png\", dpi = 1080)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbsBpU8n-tTo"
      },
      "source": [
        "def performanceTest(realtarget,predictedtarget, model_name, verbose=False):\n",
        "\n",
        "    print('\\nComputing Confusion Matrix')\n",
        "    \n",
        "    res = []\n",
        "    # Create list of threshold to be assessed\n",
        "    _, _, list_threshold = roc_curve(realtarget, predictedtarget)\n",
        "\n",
        "    # Calculate performance for each threshold\n",
        "    for thr in list_threshold:\n",
        "        p = np.copy(predictedtarget)\n",
        "\n",
        "\n",
        "        # Get AUC\n",
        "        fpr, tpr, _ = roc_curve(realtarget, p)\n",
        "        auroc_p = auc(fpr, tpr)\n",
        "\n",
        "        # Classification\n",
        "        p[p < thr] = 0; # inferior\n",
        "        p[p != 0] = 1; # sup or equal\n",
        "\n",
        "        # Get AUPR\n",
        "        precision, recall, _ = precision_recall_curve(realtarget, p)\n",
        "        aupr_p = auc(recall, precision)\n",
        "\n",
        "        # Confusion matrix\n",
        "        matrix = confusion_matrix(realtarget, p)\n",
        "\n",
        "        # Metrics\n",
        "        acc = accuracy_score(realtarget, p)\n",
        "        sens = recall_score(realtarget, p) # or recall\n",
        "        spec = matrix[0,0]/(matrix[0,0]+matrix[0,1]) # TN/TN+FP\n",
        "        pr = precision_score(realtarget, p)\n",
        "\n",
        "        df_tmp = pd.DataFrame({'Threshold': [thr], 'Accuracy': [acc],\n",
        "                               'Precision' : [pr],'Specificity': [spec],\n",
        "                               'Sensitivity': [sens],'AUC': [auroc_p],\n",
        "                               'AUPR': [aupr_p]})\n",
        "\n",
        "        res.append(df_tmp)\n",
        "\n",
        "    # The next measures are not independent from the threshold.\n",
        "    res = pd.concat(res, axis=0)\n",
        "    \n",
        "    res.to_csv(base_dir + model_name + '_thresh_precision.csv')\n",
        "    \n",
        "    res.index = pd.RangeIndex(start=0, stop=len(list_threshold), step=1)\n",
        "\n",
        "    thr_delta = res.loc[(res.Sensitivity - res.Specificity).abs().idxmin()]\n",
        "\n",
        "    thr_prec = res.loc[res.Precision.idxmax()]\n",
        "    score_loss = thr_delta.Sensitivity + thr_delta.Specificity\n",
        "\n",
        "    d_thr_delta =  dict(thr_delta)\n",
        "    d_thr_prec = dict(thr_prec)\n",
        "\n",
        "    return d_thr_delta, d_thr_prec, thr_delta\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKXIC9PD-tTp"
      },
      "source": [
        "results_file = open(base_dir + \"results.txt\", \"w\")\n",
        "results_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEf7Q6Er-tTp"
      },
      "source": [
        "# Initialize dictionary to store results\n",
        "results = {}\n",
        "\n",
        "\n",
        "# Tune and evaluate classifiers\n",
        "for classifier_label, classifier in classifiers.items():\n",
        "    # Print message to user\n",
        "    print(f\"Now tuning {classifier_label}.\")\n",
        "    \n",
        "    # Scale features via Z-score normalization\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Define steps in pipeline\n",
        "    #steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
        "    steps = [(\"classifier\", classifier)]\n",
        "    \n",
        "    # Initialize Pipeline object\n",
        "    pipeline = Pipeline(steps = steps)\n",
        "      \n",
        "    # Define parameter grid\n",
        "    param_grid = parameters[classifier_label]\n",
        "    \n",
        "    # Initialize GridSearch object\n",
        "    gscv = GridSearchCV(pipeline, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = \"precision\", refit = \"precision\")\n",
        "                      \n",
        "    # Fit gscv\n",
        "    gscv.fit(X_train, np.ravel(y_train))  \n",
        "    \n",
        "    # Get best parameters and score\n",
        "    best_params = gscv.best_params_\n",
        "    best_score = gscv.best_score_\n",
        "    \n",
        "    # Update classifier parameters and define new pipeline with tuned classifier\n",
        "    tuned_params = {item[12:]: best_params[item] for item in best_params}\n",
        "    classifier.set_params(**tuned_params)\n",
        "            \n",
        "    # Make predictions\n",
        "    if classifier_label in DECISION_FUNCTIONS:\n",
        "        y_pred = gscv.decision_function(X_test)\n",
        "    else:\n",
        "        y_pred = gscv.predict_proba(X_test)[:,1]\n",
        "    \n",
        "        \n",
        "    # Evaluate model\n",
        "    auc_roc = metrics.roc_auc_score(y_test, y_pred)\n",
        "    \n",
        "    results_file = open(base_dir + \"results_precision.txt\", \"a\")\n",
        "\n",
        "    results_file.write('\\n\\n\\n\\nModel Name: {}'.format(classifier_label))\n",
        "    results_file.write('\\nTraining AUC' + ': ' + str(np.round(best_score, 4)))\n",
        "    results_file.write('\\nTest AUC' + ': ' + str(np.round(auc_roc, 3)))\n",
        "    \n",
        "    results_p, results_prec, df_delta = performanceTest(y_test, y_pred, classifier_label)\n",
        "        \n",
        "    results_file.write('\\n\\nResults on Test Set Prediction (min delta):')\n",
        "    for y in results_p.keys():\n",
        "        results_file.write(\"\\n\" + str(y) + ': ' + str(np.round(results_p[y], 4)))\n",
        "\n",
        "    results_file.write('\\n\\nResults on Test Set Prediction (max precision):')\n",
        "    for y in results_prec.keys():\n",
        "        results_file.write(\"\\n\" + str(y) + ': ' + str(np.round(results_prec[y], 4)))\n",
        "        \n",
        "    results_file.close()\n",
        "    \n",
        "    # Save results\n",
        "    result = {\"Classifier\": gscv,\n",
        "              \"Best Parameters\": best_params,\n",
        "              \"Training AUC\": best_score,\n",
        "              \"Test AUC\": auc_roc}\n",
        "    \n",
        "    results.update({classifier_label: result})\n",
        "    \n",
        "    print(result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pPw4Owq-tTq"
      },
      "source": [
        "# Initialize auc_score dictionary\n",
        "auc_scores = {\n",
        "              \"Classifier\": [],\n",
        "              \"AUC\": [],\n",
        "              \"AUC Type\": []\n",
        "              }\n",
        "\n",
        "# Get AUC scores into dictionary\n",
        "for classifier_label in results:\n",
        "    auc_scores.update({\"Classifier\": [classifier_label] + auc_scores[\"Classifier\"],\n",
        "                       \"AUC\": [results[classifier_label][\"Training AUC\"]] + auc_scores[\"AUC\"],\n",
        "                       \"AUC Type\": [\"Training\"] + auc_scores[\"AUC Type\"]})\n",
        "    \n",
        "    auc_scores.update({\"Classifier\": [classifier_label] + auc_scores[\"Classifier\"],\n",
        "                       \"AUC\": [results[classifier_label][\"Test AUC\"]] + auc_scores[\"AUC\"],\n",
        "                       \"AUC Type\": [\"Test\"] + auc_scores[\"AUC Type\"]})\n",
        "\n",
        "# Dictionary to PandasDataFrame\n",
        "auc_scores = pd.DataFrame(auc_scores)\n",
        "\n",
        "# Set graph style\n",
        "sns.set(font_scale = 1.75)\n",
        "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
        "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
        "               'ytick.color': '0.4'})\n",
        "\n",
        "    \n",
        "# Colors\n",
        "training_color = sns.color_palette(\"RdYlBu\", 10)[1]\n",
        "test_color = sns.color_palette(\"RdYlBu\", 10)[-2]\n",
        "colors = [training_color, test_color]\n",
        "\n",
        "# Set figure size and create barplot\n",
        "f, ax = plt.subplots(figsize=(12, 9))\n",
        "\n",
        "sns.barplot(x=\"AUC\", y=\"Classifier\", hue=\"AUC Type\", palette = colors,\n",
        "            data=auc_scores)\n",
        "\n",
        "# Generate a bolded horizontal line at y = 0\n",
        "ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
        "\n",
        "# Turn frame off\n",
        "ax.set_frame_on(False)\n",
        "\n",
        "# Tight layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save Figure\n",
        "plt.savefig(\"AUC Scores.png\", dpi = 1080)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVHaIPyI-tTq"
      },
      "source": [
        "auc_scores.to_csv('auc_scores.csv')\n",
        "auc_scores"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}