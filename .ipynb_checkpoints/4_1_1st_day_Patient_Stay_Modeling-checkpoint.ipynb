{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1EiNc4SZIZ6",
    "outputId": "1343be9c-b505-4986-9f60-b3390c0c5cff"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Compare Algorithms\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pgPyV6ODQYi0"
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 100, \"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDbIj2MXuS_D"
   },
   "source": [
    "\n",
    "* try optimizing using the new function\n",
    "* add insulin dose as predictor variable\n",
    "* create a new cohort with the slopes in between the prior glucose and try it\n",
    "* use SMOTE for generating more training data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "u1IDuT-Ea3lA"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File event_df.csv does not exist: 'event_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8d822bce4c45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m'./'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfull_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'event_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfull_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labresult'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File event_df.csv does not exist: 'event_df.csv'"
     ]
    }
   ],
   "source": [
    "name = '2h_final'\n",
    "\n",
    "base_dir =  './'\n",
    "\n",
    "full_df = pd.read_csv('event_df.csv')\n",
    "full_df['Y'] = (full_df['labresult'] < 72).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "ggzatr_nLX_h",
    "outputId": "f1cf7cf5-a5e2-472a-eee9-87a42157e117"
   },
   "outputs": [],
   "source": [
    "full_df = full_df.drop(['labresult'], axis = 1)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZigJa4G3ofw",
    "outputId": "e19cfb32-af6a-4cd8-db35-1b8312136a75"
   },
   "outputs": [],
   "source": [
    "full_df.isna().mean().round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9RxXuV4Ugk5",
    "outputId": "e3cb8bdd-0225-4785-a423-adefb99903aa"
   },
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-t7nYFddPf_y"
   },
   "outputs": [],
   "source": [
    "model_df = full_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "ZekG9-Cd5rdy",
    "outputId": "2b4750d2-4ef5-4c81-8e7e-3d707066d0cf"
   },
   "outputs": [],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "C7QPuhe0qsCI",
    "outputId": "93175096-cee9-48a5-f877-48a7958a8e80"
   },
   "outputs": [],
   "source": [
    "model_df.groupby(\"Y\").mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uF2GeASm63ba",
    "outputId": "04abc8e7-a637-4b42-f54a-9590bdba0963"
   },
   "outputs": [],
   "source": [
    "sum(model_df[\"Y\"])/len(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCOWSaCj4eyo"
   },
   "source": [
    "# Creating Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbeFHP9mbuRy"
   },
   "outputs": [],
   "source": [
    "#Add in stratify to ensure equal label distribution in test/train\n",
    "train, test, train_labels, test_labels = train_test_split(model_df.drop(['Y'], axis = 1),\n",
    "                                                          model_df['Y'],\n",
    "                                                          test_size=0.15,\n",
    "                                                          random_state=100, stratify = model_df['Y'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lz8ARRMsb0H"
   },
   "outputs": [],
   "source": [
    "pred_vars = train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37IsJxGPkMDb",
    "outputId": "9a193874-ae1b-48b9-ee15-7efa6a7a5f04"
   },
   "outputs": [],
   "source": [
    "sum(train_labels)/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMIAKarLxFM6"
   },
   "outputs": [],
   "source": [
    "smote = False\n",
    "\n",
    "if(smote):\n",
    "  train, train_labels = SMOTE().fit_resample(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRu_J4w3tV4G"
   },
   "outputs": [],
   "source": [
    "under = False\n",
    "\n",
    "if(under):\n",
    "\n",
    "  # Undersampling traning dataframe for majority class\n",
    "  train_tmp = train.copy()\n",
    "  train_tmp['Y'] = train_labels\n",
    "\n",
    "  # Downsample majority class\n",
    "  df_majority_downsampled = resample(train_tmp[train_tmp['Y'] == 0], \n",
    "                                  replace=False,    # sample without replacement\n",
    "                                  n_samples=len(train_tmp[train_tmp['Y'] == 1]),     # to match minority class\n",
    "                                  random_state=123) # reproducible results\n",
    "  \n",
    "  # Combine minority class with downsampled majority class\n",
    "  train = pd.concat([df_majority_downsampled, train_tmp[train_tmp['Y'] == 1]])\n",
    "  \n",
    "  # Display new class counts\n",
    "  print(train.Y.value_counts())\n",
    "  train_labels = train.Y\n",
    "  train = train.drop(columns=['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OMT1qZXuDpw",
    "outputId": "f4b20782-6478-4ebf-f40f-ec63dd5619e4"
   },
   "outputs": [],
   "source": [
    "print('Training Dataset Length: ' + str(len(train)))\n",
    "print('Testing Dataset Length: ' + str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xxdk33XqsC3A",
    "outputId": "96e2ae7a-b391-4513-fc84-3ad9127cc7e1"
   },
   "outputs": [],
   "source": [
    "sum(train_labels)/len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_Z8Uo_34lWI"
   },
   "source": [
    "# Defining Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8-NTd2ala8p"
   },
   "outputs": [],
   "source": [
    "results_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0z0VIy2zap0C"
   },
   "outputs": [],
   "source": [
    "def grid_search_wrapper(clf, param_grid, refit_score='roc_auc'):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "\n",
    "    scorers_list = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall']\n",
    "\n",
    "    cross_val = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=cross_val, scoring= scorers_list, refit = refit_score, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(train, train_labels)\n",
    "\n",
    "    # make the predictions\n",
    "    y_probs = grid_search.predict_proba(test)[:,1]\n",
    "    y_pred = grid_search.predict(test)\n",
    "\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print('Best Score for {} on Train Set: {}'.format(refit_score, grid_search.best_score_))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    results, results_prec, df_delta = performanceTest(test_labels, y_probs)\n",
    "\n",
    "    results_list.append(df_delta)\n",
    "\n",
    "    print('\\nResults on Test Set Prediction (min delta):')\n",
    "    for y in results.keys():\n",
    "      print(str(y) + ': ' + str(np.round(results[y], 4)))\n",
    "\n",
    "    print('\\nResults on Test Set Prediction (max precision):')\n",
    "    for y in results_prec.keys():\n",
    "      print(str(y) + ': ' + str(np.round(results_prec[y], 4)))\n",
    "\n",
    "    # print(roc_auc_score(test_labels, y_pred))\n",
    "    # print(recall_score(test_labels, y_pred))\n",
    "    # print(precision_score(test_labels, y_pred))\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score))\n",
    "    print(pd.DataFrame(confusion_matrix(test_labels, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "      \n",
    "\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXo5iw7OanL5"
   },
   "outputs": [],
   "source": [
    "def performanceTest(realtarget,predictedtarget,verbose=False):\n",
    "  res = []\n",
    "  # Create list of threshold to be assessed\n",
    "  _, _, list_threshold = roc_curve(realtarget, predictedtarget)\n",
    "\n",
    "  # Calculate performance for each threshold\n",
    "  for thr in list_threshold:\n",
    "    p = np.copy(predictedtarget)\n",
    "  \n",
    "\n",
    "    # Get AUC\n",
    "    fpr, tpr, _ = roc_curve(realtarget, p)\n",
    "    auroc_p = auc(fpr, tpr)\n",
    "\n",
    "    # Classification\n",
    "    p[p < thr] = 0; # inferior\n",
    "    p[p != 0] = 1; # sup or equal\n",
    "\n",
    "    # Get AUPR\n",
    "    precision, recall, _ = precision_recall_curve(realtarget, p)\n",
    "    aupr_p = auc(recall, precision)\n",
    "\n",
    "    # Confusion matrix\n",
    "    matrix = confusion_matrix(realtarget, p)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(realtarget, p)\n",
    "    sens = recall_score(realtarget, p) # or recall\n",
    "    spec = matrix[0,0]/(matrix[0,0]+matrix[0,1]) # TN/TN+FP\n",
    "    pr = precision_score(realtarget, p)\n",
    "\n",
    "    df_tmp = pd.DataFrame({'Threshold': [thr], 'Accuracy': [acc],\n",
    "                           'Precision' : [pr],'Specificity': [spec],\n",
    "                           'Sensitivity': [sens],'AUC': [auroc_p],\n",
    "                           'AUPR': [aupr_p], 'Model' : curr_model})\n",
    "      \n",
    "    res.append(df_tmp)\n",
    "\n",
    "  # The next measures are not independent from the threshold.\n",
    "  res = pd.concat(res, axis=0)\n",
    "  res.index = pd.RangeIndex(start=0, stop=len(list_threshold), step=1)\n",
    "  \n",
    "  thr_delta = res.loc[(res.Sensitivity - res.Specificity).abs().idxmin()]\n",
    "  if verbose:\n",
    "    print('\\n')\n",
    "    print(f'Minimizing \\u0394(Sen-Spec): AUC={thr_delta.AUC:0.2f}')\n",
    "    print(f'Minimizing \\u0394(Sen-Spec): AUPR={thr_delta.AUPR:0.2f}')\n",
    "    print(f'Minimizing \\u0394(Sen-Spec): Sense={thr_delta.Sensitivity:0.2f}')\n",
    "    print(f'Minimizing \\u0394(Sen-Spec): Spec={thr_delta.Specificity:0.2f}')\n",
    "\n",
    "  thr_prec = res.loc[res.Precision.idxmax()]\n",
    "  score_loss = thr_delta.Sensitivity + thr_delta.Specificity\n",
    "\n",
    "  d_thr_delta =  dict(thr_delta)\n",
    "  del d_thr_delta['Model']\n",
    "  d_thr_prec = dict(thr_prec)\n",
    "  del d_thr_prec['Model']\n",
    "\n",
    "  \n",
    "  print(thr_delta)\n",
    "  return d_thr_delta, d_thr_prec, thr_delta\n",
    "  #return thr_delta.AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12eB5Ipo4pNY"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZbH7_2sUM41"
   },
   "source": [
    "Things to try:\n",
    "\n",
    "* SK Learn Feature Selection\n",
    "* Ensemble Models\n",
    "* Adding in Medication\n",
    "* Each Patient is only considered once, add a feature if they had a hypoglycemic event in previous patient stay\n",
    "* Minimum glucose during observation window, maybe std?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nTMlHZOL7s1w",
    "outputId": "da5c319c-9405-424d-db32-6361069b86ac"
   },
   "outputs": [],
   "source": [
    "curr_model = 'LogisticRegression'\n",
    "clf = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "    'C' : [100, 10, 1.0, 0.1, 0.01],\n",
    "    'penalty': ['l2', 'l1']\n",
    "}\n",
    "\n",
    "grid_search = grid_search_wrapper(clf, param_grid)\n",
    "\n",
    "\n",
    "importance = grid_search.best_estimator_.fit(train, train_labels).coef_[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (40,8))\n",
    "plt.bar(np.arange(0, len(importance)), height = importance)\n",
    "plt.xticks(np.arange(0, len(importance)), labels = pred_vars, fontsize = 14, rotation = 'vertical')\n",
    "plt.title(\"Feature Importance for Log Reg Model\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(base_dir + 'LR feature importance.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGyCShoYYDju",
    "outputId": "c05799d1-390e-416e-d7ec-50a6db2d2870"
   },
   "outputs": [],
   "source": [
    "curr_model = 'Random Forest'\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [3, 5, 10], \n",
    "    'n_estimators' : [100, 200, 300],\n",
    "    'max_depth': [3, 5, 15, 25],\n",
    "    'max_features': [3, 5, 10, 20, 40]\n",
    "}\n",
    "\n",
    "results = grid_search_wrapper(clf, param_grid)\n",
    "\n",
    "importance = results.best_estimator_.fit(train, train_labels).feature_importances_\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (40,8))\n",
    "plt.bar(np.arange(0, len(importance)), height = importance)\n",
    "plt.xticks(np.arange(0, len(importance)), labels = pred_vars, fontsize = 10, rotation = 'vertical')\n",
    "plt.title(\"Feature Importance for RF Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(base_dir + 'RF feature importance.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5JOKFUo49yN"
   },
   "outputs": [],
   "source": [
    "curr_model = 'XGBoost'\n",
    "\n",
    "clf = XGBClassifier(n_jobs=-1)\n",
    "\n",
    "param_grid = {\"max_depth\": [6,15],\n",
    "              \"min_child_weight\" : [3,6],\n",
    "              \"n_estimators\": [200],\n",
    "              \"learning_rate\": [0.01,0.1,0.5],\n",
    "              \"colsample_bytree\": [0.5,0.7],\n",
    "              \"subsample\": [1],\n",
    "              \"max_delta_step\": [0.1,3,10],\n",
    "              \"colsample_bylevel\": [0.6, 0.7],\n",
    "              \"base_score\": [sum(train_labels)/len(train),0.1,0.5],\n",
    "              }\n",
    "\n",
    "results = grid_search_wrapper(clf, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qRAprkLligK"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import table \n",
    "results_df = pd.concat(results_list, axis=1)\n",
    "finaldf = results_df.T\n",
    "\n",
    "ax = plt.subplot(111, frame_on=False) # no visible frame\n",
    "ax.xaxis.set_visible(False)  # hide the x axis\n",
    "ax.yaxis.set_visible(False)  # hide the y axis\n",
    "table(ax, finaldf)  # where df is your data frame\n",
    "plt.tight_layout()\n",
    "plt.savefig(base_dir + 'results_cv.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtPZI21IpVCu"
   },
   "outputs": [],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_XdKTDloLdR"
   },
   "source": [
    "# Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jt4J-5PE2OPh"
   },
   "outputs": [],
   "source": [
    "def run_exps(X_train: pd.DataFrame , y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame):\n",
    "  '''\n",
    "  Lightweight script to test many models and find winners\n",
    "  :param X_train: training split\n",
    "  :param y_train: training target vector\n",
    "  :param X_test: test split\n",
    "  :param y_test: test target vector\n",
    "  :return: DataFrame of predictions\n",
    "  '''\n",
    "  dfs = []\n",
    "  global models\n",
    "  models = [\n",
    " #           ('LinReg', LinearRegression()),\n",
    "            ('LogReg', LogisticRegression()), \n",
    "            ('RF', RandomForestClassifier())\n",
    "            # ,\n",
    "            # ('KNN', KNeighborsClassifier()),\n",
    "            # ('SVM', SVC(probability=True)), \n",
    "            # ('GNB', GaussianNB()),\n",
    "            # ('XGB', XGBClassifier()),\n",
    "            # ('AdaBoost', AdaBoostClassifier()),\n",
    "            # ('DecisionTree', DecisionTreeClassifier()),\n",
    "            # ('Bagging', BaggingClassifier()),\n",
    "            # ('GradientBoosting', GradientBoostingClassifier())\n",
    "          ]\n",
    "    \n",
    "  results = []\n",
    "  names = []\n",
    "  scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "  target_names = ['Control', 'Hypoglycemic']\n",
    "  probs = {}\n",
    "  for name, model in models:\n",
    "          kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=90210)\n",
    "          cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "          clf = model.fit(X_train, y_train)\n",
    "\n",
    "          y_pred = clf.predict(X_test)\n",
    "          y_probs = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "          print(name)\n",
    "          print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "          print(roc_auc_score(y_test, y_probs))\n",
    "          results.append(cv_results)\n",
    "          names.append(name)\n",
    "          this_df = pd.DataFrame(cv_results)\n",
    "          this_df['model'] = name\n",
    "          dfs.append(this_df)\n",
    "          probs[name] = y_probs\n",
    "  final = pd.concat(dfs, ignore_index=True)\n",
    "  \n",
    "\n",
    "  return final, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IO8hJMFm8VDN",
    "outputId": "422fabe5-3724-452b-ec4e-7a40534f3834"
   },
   "outputs": [],
   "source": [
    "final, probs = run_exps(train, train_labels, test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jR5hBQW58Wk0"
   },
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "for model in list(set(final.model.values)):\n",
    "    df_t = final.loc[final.model == model]\n",
    "    #bootstrap = df_t.sample(n=30, replace=True)\n",
    "    #bootstraps.append(bootstrap)\n",
    "    bootstraps.append(df_t)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics\n",
    "\n",
    "## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2ajakDsDQOp"
   },
   "outputs": [],
   "source": [
    "results_long_nofit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAf-Y-Ab8XrJ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "sns.set(font_scale=2.5)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.savefig(base_dir + 'benchmark_models_performance.png',dpi=300)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4.1 1st day Patient Stay Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
